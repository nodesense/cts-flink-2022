{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd15340b-6310-47d5-97a5-7a4f0c99331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyflink.common.time import Instant\n",
    "\n",
    "from pyflink.common import Types\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import (DataTypes, TableDescriptor, Schema, StreamTableEnvironment)\n",
    "from pyflink.table.expressions import lit, col\n",
    "from pyflink.table.udf import udaf\n",
    "from pyflink.table.window import Tumble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29ebd9d-b780-4880-99ed-f1faebae41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pandas_udaf():\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.set_parallelism(1)\n",
    "    t_env = StreamTableEnvironment.create(stream_execution_environment=env)\n",
    "\n",
    "    # define the source with watermark definition\n",
    "    ds = env.from_collection(\n",
    "        collection=[\n",
    "            (Instant.of_epoch_milli(1000), 'Alice', 110.1),\n",
    "            (Instant.of_epoch_milli(4000), 'Bob', 30.2),\n",
    "            (Instant.of_epoch_milli(3000), 'Alice', 20.0),\n",
    "            (Instant.of_epoch_milli(2000), 'Bob', 53.1),\n",
    "            (Instant.of_epoch_milli(5000), 'Alice', 13.1),\n",
    "            (Instant.of_epoch_milli(3000), 'Bob', 3.1),\n",
    "            (Instant.of_epoch_milli(7000), 'Bob', 16.1),\n",
    "            (Instant.of_epoch_milli(10000), 'Alice', 20.1)\n",
    "        ],\n",
    "        type_info=Types.ROW([Types.INSTANT(), Types.STRING(), Types.FLOAT()]))\n",
    "\n",
    "    table = t_env.from_data_stream(\n",
    "        ds,\n",
    "        Schema.new_builder()\n",
    "              .column_by_expression(\"ts\", \"CAST(f0 AS TIMESTAMP_LTZ(3))\")\n",
    "              .column(\"f1\", DataTypes.STRING())\n",
    "              .column(\"f2\", DataTypes.FLOAT())\n",
    "              .watermark(\"ts\", \"ts - INTERVAL '3' SECOND\")\n",
    "              .build()\n",
    "    ).alias(\"ts\", \"name\", \"price\")\n",
    "\n",
    "    # define the sink\n",
    "    t_env.create_temporary_table(\n",
    "        'sink',\n",
    "        TableDescriptor.for_connector('print')\n",
    "                       .schema(Schema.new_builder()\n",
    "                               .column('name', DataTypes.STRING())\n",
    "                               .column('total_price', DataTypes.FLOAT())\n",
    "                               .column('w_start', DataTypes.TIMESTAMP_LTZ())\n",
    "                               .column('w_end', DataTypes.TIMESTAMP_LTZ())\n",
    "                               .build())\n",
    "                       .build())\n",
    "\n",
    "    @udaf(result_type=DataTypes.FLOAT(), func_type=\"pandas\")\n",
    "    def mean_udaf(v):\n",
    "        return v.mean()\n",
    "\n",
    "    # define the tumble window operation\n",
    "    table = table.window(Tumble.over(lit(5).seconds).on(col(\"ts\")).alias(\"w\")) \\\n",
    "                 .group_by(col('name'), col('w')) \\\n",
    "                 .select(col('name'), mean_udaf(col('price')), col(\"w\").start, col(\"w\").end)\n",
    "\n",
    "    # submit for execution\n",
    "    table.execute_insert('sink') \\\n",
    "         .wait()\n",
    "    # remove .wait if submitting to a remote cluster, refer to\n",
    "    # https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/python/faq/#wait-for-jobs-to-finish-when-executing-jobs-in-mini-cluster\n",
    "    # for more details\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47c8051-2a44-4ff2-9de5-dc77ea2271e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/flink-dev/lib/python3.8/site-packages/pyflink/table/utils.py:55: FutureWarning: Schema passed to names= option, please pass schema= explicitly. Will raise exception in future\n",
      "  return pa.RecordBatch.from_arrays(arrays, schema)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+I[Alice, 65.05, 1970-01-01T00:00:00Z, 1970-01-01T00:00:05Z]\n",
      "+I[Bob, 28.800001, 1970-01-01T00:00:00Z, 1970-01-01T00:00:05Z]\n",
      "+I[Bob, 16.1, 1970-01-01T00:00:05Z, 1970-01-01T00:00:10Z]\n",
      "+I[Alice, 13.1, 1970-01-01T00:00:05Z, 1970-01-01T00:00:10Z]\n",
      "+I[Alice, 20.1, 1970-01-01T00:00:10Z, 1970-01-01T00:00:15Z]\n"
     ]
    }
   ],
   "source": [
    "pandas_udaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10534cfc-a2a5-4bc3-8c4b-71fd9944114a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
