{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5820280-6dd4-4dc7-aa54-25f7e631c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.table import EnvironmentSettings, TableEnvironment, DataTypes, CsvTableSource\n",
    "import datetime\n",
    "from pyflink.table.expressions import col\n",
    "from pyflink.table.window import Over, GroupWindow\n",
    "from pyflink.table.expressions import col, UNBOUNDED_RANGE, CURRENT_RANGE\n",
    "from pyflink.table.udf import udf\n",
    "\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.common.typeinfo import Types\n",
    "from pyflink.datastream.functions import RuntimeContext, MapFunction\n",
    "from pyflink.table import StreamTableEnvironment\n",
    "from pyflink.datastream.state import ValueStateDescriptor\n",
    "# create a batch TableEnvironment\n",
    "#env_settings = EnvironmentSettings.in_streaming_mode()\n",
    "#table_env = TableEnvironment.create(env_settings)\n",
    "#table_env.get_config().get_configuration().set_string(\"pipeline.jars\", \"file:///opt/flink-1.15.0/lib/*.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931e3893-8695-4cdd-9ef3-8abdacbae41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/flink-1.15.0/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    }
   ],
   "source": [
    "env = StreamExecutionEnvironment.get_execution_environment()\n",
    "table_env = StreamTableEnvironment.create(stream_execution_environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b0fbf3-64d5-40a3-a49e-bcf9c8100b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registered Tables List\n",
      "['invoices']\n",
      "\n",
      "Financial Trxs Schema\n",
      "(\n",
      "  `InvoiceNo` STRING,\n",
      "  `StockCode` STRING,\n",
      "  `Description` STRING,\n",
      "  `Quantity` DOUBLE,\n",
      "  `InvoiceDate` TIMESTAMP(3) *ROWTIME*,\n",
      "  `UnitPrice` DOUBLE,\n",
      "  `CustomerID` STRING,\n",
      "  `Country` STRING,\n",
      "  WATERMARK FOR `InvoiceDate`: TIMESTAMP(3) AS `InvoiceDate` - INTERVAL '1' SECOND\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country\n",
    "# 536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/01/2010 8:26,2.55,17850,United Kingdom\n",
    "\n",
    "source_ddl = \"\"\"\n",
    "            CREATE TABLE invoices (\n",
    "                   InvoiceNo STRING,\n",
    "                   StockCode  STRING,\n",
    "                   Description  STRING,\n",
    "                   Quantity DOUBLE,\n",
    "                   InvoiceDate TIMESTAMP(3),\n",
    "                   UnitPrice DOUBLE,\n",
    "                   CustomerID STRING,\n",
    "                   Country STRING,\n",
    "                   WATERMARK FOR InvoiceDate AS InvoiceDate - INTERVAL '1' SECOND\n",
    "\n",
    "                    ) WITH (\n",
    "                      'connector' = 'filesystem',          \n",
    "                      'path' = 'file:///home/krish/flink/data/ecomm/ecommerce-small.csv', \n",
    "                      'format' = 'csv'\n",
    "                    )\"\"\"\n",
    "\n",
    "\n",
    "table_env.execute_sql(source_ddl) \n",
    "\n",
    "invoices = table_env.from_path(\"invoices\")\n",
    "##############################\n",
    "print('\\nRegistered Tables List')\n",
    "print(table_env.list_tables())\n",
    "\n",
    "print('\\nFinancial Trxs Schema')\n",
    "invoices.print_schema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935f2f43-3d3b-47a5-8c9e-7f1bc792e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------------+--------------------------------+--------------------------------+--------------------------------+-------------------------+--------------------------------+--------------------------------+--------------------------------+\n",
      "| op |                      InvoiceNo |                      StockCode |                    Description |                       Quantity |             InvoiceDate |                      UnitPrice |                     CustomerID |                        Country |\n",
      "+----+--------------------------------+--------------------------------+--------------------------------+--------------------------------+-------------------------+--------------------------------+--------------------------------+--------------------------------+\n",
      "| +I |                         536365 |                         85123A | WHITE HANGING HEART T-LIGHT... |                            6.0 | 2010-12-01 08:26:00.000 |                           2.55 |                          17850 |                 United Kingdom |\n",
      "| +I |                         536365 |                          71053 |            WHITE METAL LANTERN |                            6.0 | 2010-12-01 08:26:00.000 |                           3.39 |                          17850 |                 United Kingdom |\n",
      "| +I |                         536365 |                         84406B | CREAM CUPID HEARTS COAT HANGER |                            8.0 | 2010-12-01 08:26:00.000 |                           2.75 |                          17850 |                 United Kingdom |\n",
      "+----+--------------------------------+--------------------------------+--------------------------------+--------------------------------+-------------------------+--------------------------------+--------------------------------+--------------------------------+\n",
      "3 rows in set\n"
     ]
    }
   ],
   "source": [
    "invoices.fetch(3).execute().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fff3864-f34e-4c31-9109-a5f146e760f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = invoices.get_schema()\n",
    "\n",
    "ds = table_env.to_append_stream(\n",
    "    table_env.from_path('invoices'),\n",
    "    Types.ROW([Types.STRING(), Types.STRING(), Types.STRING(), Types.DOUBLE(), \n",
    "                Types.SQL_TIMESTAMP(), Types.DOUBLE(),Types.STRING(), Types.STRING()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ba8069-b81c-47ad-b1a4-6157b3d6a81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.datastream.data_stream.DataStreamSink at 0x7fc7583cefd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7054f2ad-2340-48d8-a739-b62592194fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4> +I[536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6.0,2010-12-01 08:26:00,2.55,17850,United Kingdom]\n",
      "4> +I[536365,71053,WHITE METAL LANTERN,6.0,2010-12-01 08:26:00,3.39,17850,United Kingdom]\n",
      "4> +I[536365,84406B,CREAM CUPID HEARTS COAT HANGER,8.0,2010-12-01 08:26:00,2.75,17850,United Kingdom]\n",
      "4> +I[536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6.0,2010-12-01 08:26:00,3.39,17850,United Kingdom]\n",
      "4> +I[536365,84029E,RED WOOLLY HOTTIE WHITE HEART.,6.0,2010-12-01 08:26:00,3.39,17850,United Kingdom]\n",
      "4> +I[536365,22752,SET 7 BABUSHKA NESTING BOXES,2.0,2010-12-01 08:26:00,7.65,17850,United Kingdom]\n",
      "4> +I[536365,21730,GLASS STAR FROSTED T-LIGHT HOLDER,6.0,2010-12-01 08:26:00,4.25,17850,United Kingdom]\n",
      "4> +I[536366,22633,HAND WARMER UNION JACK,6.0,2010-12-01 08:28:00,1.85,17850,United Kingdom]\n",
      "4> +I[536366,22632,HAND WARMER RED POLKA DOT,6.0,2010-12-01 08:28:00,1.85,17850,United Kingdom]\n",
      "4> +I[536367,84879,ASSORTED COLOUR BIRD ORNAMENT,32.0,2010-12-01 08:34:00,1.69,13047,United Kingdom]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.common.job_execution_result.JobExecutionResult at 0x7fc707faa7c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0bc881-f9be-4d41-b8ba-7388d427e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMapFunction(MapFunction):\n",
    "\n",
    "    def open(self, runtime_context: RuntimeContext):\n",
    "        print(\"MyMapFunction open\")\n",
    "        state_desc = ValueStateDescriptor('cnt', Types.LONG())\n",
    "        #Define value state\n",
    "        self.cnt_state = runtime_context.get_state(state_desc)\n",
    "        print (\"Count state is \", self.cnt_state)\n",
    "        \n",
    "\n",
    "    def map(self, value):\n",
    "        print(\"Value is \", value, value[0], value[2])\n",
    "        cnt = self.cnt_state.value()\n",
    "        print(\"MyMapFunction map\", cnt)\n",
    "        if cnt is None:\n",
    "            cnt = 0\n",
    "\n",
    "        new_cnt = cnt + 1\n",
    "        self.cnt_state.update(new_cnt)\n",
    "        return value[0], new_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0abf3a3-b25e-4eaf-94af-0bd99c7b98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#3. Define execution logic\n",
    "ds2 = ds.key_by(lambda a: a[0]) \\\n",
    "       .map(MyMapFunction(), output_type=Types.TUPLE([Types.LONG(), Types.LONG()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd131ba-17f0-4d50-9734-6b1e20aede16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMapFunction open\n",
      "Count state is  <pyflink.fn_execution.state_impl.SynchronousValueRuntimeState object at 0x7fc707e883d0>\n",
      "MyMapFunction open\n",
      "Count state is  <pyflink.fn_execution.state_impl.SynchronousValueRuntimeState object at 0x7fc707ea4760>\n",
      "Value is  Row(f0='536367', f1='84879', f2='ASSORTED COLOUR BIRD ORNAMENT', f3=32.0, f4=datetime.datetime(2010, 12, 1, 8, 34), f5=1.69, f6='13047', f7='United Kingdom') 536367 ASSORTED COLOUR BIRD ORNAMENT\n",
      "Value is  Row(f0='536366', f1='22633', f2='HAND WARMER UNION JACK', f3=6.0, f4=datetime.datetime(2010, 12, 1, 8, 28), f5=1.85, f6='17850', f7='United Kingdom') 536366 HAND WARMER UNION JACK\n",
      "MyMapFunction map None\n",
      "MyMapFunction map None\n",
      "MyMapFunction open\n",
      "Count state is  <pyflink.fn_execution.state_impl.SynchronousValueRuntimeState object at 0x7fc707e493d0>\n",
      "Value is  Row(f0='536365', f1='85123A', f2='WHITE HANGING HEART T-LIGHT HOLDER', f3=6.0, f4=datetime.datetime(2010, 12, 1, 8, 26), f5=2.55, f6='17850', f7='United Kingdom') 536365 WHITE HANGING HEART T-LIGHT HOLDER\n",
      "MyMapFunction map None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n",
      "    response = task()\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n",
      "    lambda: self.create_worker().do_instruction(request), request)\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 606, in do_instruction\n",
      "    return getattr(self, request_type)(\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n",
      "    bundle_processor.process_bundle(instruction_id))\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 999, in process_bundle\n",
      "    input_op_by_transform_id[element.transform_id].process_encoded(\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n",
      "    self.output(decoded_value)\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 104, in pyflink.fn_execution.beam.beam_operations_fast.IntermediateOutputProcessor.process_outputs\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 92, in pyflink.fn_execution.beam.beam_operations_fast.NetworkOutputProcessor.process_outputs\n",
      "  File \"pyflink/fn_execution/beam/beam_coder_impl_fast.pyx\", line 101, in pyflink.fn_execution.beam.beam_coder_impl_fast.FlinkLengthPrefixCoderBeamWrapper.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 270, in pyflink.fn_execution.coder_impl_fast.IterableCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 398, in pyflink.fn_execution.coder_impl_fast.RowCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 877, in pyflink.fn_execution.coder_impl_fast.TupleCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 535, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 536, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n",
      "TypeError: an integer is required\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n",
      "    response = task()\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n",
      "    lambda: self.create_worker().do_instruction(request), request)\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 606, in do_instruction\n",
      "    return getattr(self, request_type)(\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n",
      "    bundle_processor.process_bundle(instruction_id))\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 999, in process_bundle\n",
      "    input_op_by_transform_id[element.transform_id].process_encoded(\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n",
      "    self.output(decoded_value)\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 104, in pyflink.fn_execution.beam.beam_operations_fast.IntermediateOutputProcessor.process_outputs\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 92, in pyflink.fn_execution.beam.beam_operations_fast.NetworkOutputProcessor.process_outputs\n",
      "  File \"pyflink/fn_execution/beam/beam_coder_impl_fast.pyx\", line 101, in pyflink.fn_execution.beam.beam_coder_impl_fast.FlinkLengthPrefixCoderBeamWrapper.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 270, in pyflink.fn_execution.coder_impl_fast.IterableCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 398, in pyflink.fn_execution.coder_impl_fast.RowCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 877, in pyflink.fn_execution.coder_impl_fast.TupleCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 535, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 536, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n",
      "TypeError: an integer is required\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n",
      "    response = task()\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n",
      "    lambda: self.create_worker().do_instruction(request), request)\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 606, in do_instruction\n",
      "    return getattr(self, request_type)(\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n",
      "    bundle_processor.process_bundle(instruction_id))\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 999, in process_bundle\n",
      "    input_op_by_transform_id[element.transform_id].process_encoded(\n",
      "  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n",
      "    self.output(decoded_value)\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 104, in pyflink.fn_execution.beam.beam_operations_fast.IntermediateOutputProcessor.process_outputs\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n",
      "  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 92, in pyflink.fn_execution.beam.beam_operations_fast.NetworkOutputProcessor.process_outputs\n",
      "  File \"pyflink/fn_execution/beam/beam_coder_impl_fast.pyx\", line 101, in pyflink.fn_execution.beam.beam_coder_impl_fast.FlinkLengthPrefixCoderBeamWrapper.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 270, in pyflink.fn_execution.coder_impl_fast.IterableCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 398, in pyflink.fn_execution.coder_impl_fast.RowCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 877, in pyflink.fn_execution.coder_impl_fast.TupleCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 535, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n",
      "  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 536, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n",
      "TypeError: an integer is required\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o0.execute.\n: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:144)\n\tat org.apache.flink.runtime.minicluster.MiniClusterJobClient.lambda$getJobExecutionResult$3(MiniClusterJobClient.java:141)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$1(AkkaInvocationHandler.java:259)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1389)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)\n\tat akka.dispatch.OnComplete.internal(Future.scala:300)\n\tat akka.dispatch.OnComplete.internal(Future.scala:297)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:68)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)\n\tat akka.pattern.PromiseActorRef.$bang(AskSupport.scala:621)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:532)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)\nCaused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy\n\tat org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138)\n\tat org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:301)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:291)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:282)\n\tat org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:739)\n\tat org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:78)\n\tat org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:443)\n\tat sun.reflect.GeneratedMethodAccessor18.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:304)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:302)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:217)\n\tat org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:78)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:163)\n\tat akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)\n\tat akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)\n\tat scala.PartialFunction.applyOrElse(PartialFunction.scala:123)\n\tat scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)\n\tat akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:535)\n\tat akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:580)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:548)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\t... 4 more\nCaused by: java.lang.RuntimeException: Error while waiting for BeamPythonFunctionRunner flush\n\tat org.apache.flink.streaming.api.operators.python.AbstractExternalPythonFunctionOperator.invokeFinishBundle(AbstractExternalPythonFunctionOperator.java:106)\n\tat org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.processWatermark(AbstractPythonFunctionOperator.java:184)\n\tat org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitWatermark(OneInputStreamTask.java:239)\n\tat org.apache.flink.streaming.runtime.watermarkstatus.StatusWatermarkValve.findAndOutputNewMinWatermarkAcrossAlignedChannels(StatusWatermarkValve.java:200)\n\tat org.apache.flink.streaming.runtime.watermarkstatus.StatusWatermarkValve.inputWatermark(StatusWatermarkValve.java:105)\n\tat org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:136)\n\tat org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:105)\n\tat org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:519)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:203)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:804)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:753)\n\tat org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:948)\n\tat org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:927)\n\tat org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:741)\n\tat org.apache.flink.runtime.taskmanager.Task.run(Task.java:563)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.RuntimeException: Failed to close remote bundle\n\tat org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.finishBundle(BeamPythonFunctionRunner.java:382)\n\tat org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.flush(BeamPythonFunctionRunner.java:366)\n\tat org.apache.flink.streaming.api.operators.python.AbstractExternalPythonFunctionOperator.lambda$invokeFinishBundle$0(AbstractExternalPythonFunctionOperator.java:85)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Error received from SDK harness for instruction 1: Traceback (most recent call last):\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n    response = task()\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n    lambda: self.create_worker().do_instruction(request), request)\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 606, in do_instruction\n    return getattr(self, request_type)(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n    bundle_processor.process_bundle(instruction_id))\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 999, in process_bundle\n    input_op_by_transform_id[element.transform_id].process_encoded(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n    self.output(decoded_value)\n  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 104, in pyflink.fn_execution.beam.beam_operations_fast.IntermediateOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 92, in pyflink.fn_execution.beam.beam_operations_fast.NetworkOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_coder_impl_fast.pyx\", line 101, in pyflink.fn_execution.beam.beam_coder_impl_fast.FlinkLengthPrefixCoderBeamWrapper.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 270, in pyflink.fn_execution.coder_impl_fast.IterableCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 398, in pyflink.fn_execution.coder_impl_fast.RowCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 877, in pyflink.fn_execution.coder_impl_fast.TupleCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 535, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 536, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\nTypeError: an integer is required\n\n\tat java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)\n\tat java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)\n\tat org.apache.beam.sdk.util.MoreFutures.get(MoreFutures.java:60)\n\tat org.apache.beam.runners.fnexecution.control.SdkHarnessClient$BundleProcessor$ActiveBundle.close(SdkHarnessClient.java:504)\n\tat org.apache.beam.runners.fnexecution.control.DefaultJobBundleFactory$SimpleStageBundleFactory$1.close(DefaultJobBundleFactory.java:555)\n\tat org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.finishBundle(BeamPythonFunctionRunner.java:380)\n\t... 7 more\nCaused by: java.lang.RuntimeException: Error received from SDK harness for instruction 1: Traceback (most recent call last):\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n    response = task()\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n    lambda: self.create_worker().do_instruction(request), request)\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 606, in do_instruction\n    return getattr(self, request_type)(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n    bundle_processor.process_bundle(instruction_id))\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 999, in process_bundle\n    input_op_by_transform_id[element.transform_id].process_encoded(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n    self.output(decoded_value)\n  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 104, in pyflink.fn_execution.beam.beam_operations_fast.IntermediateOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 92, in pyflink.fn_execution.beam.beam_operations_fast.NetworkOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_coder_impl_fast.pyx\", line 101, in pyflink.fn_execution.beam.beam_coder_impl_fast.FlinkLengthPrefixCoderBeamWrapper.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 270, in pyflink.fn_execution.coder_impl_fast.IterableCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 398, in pyflink.fn_execution.coder_impl_fast.RowCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 877, in pyflink.fn_execution.coder_impl_fast.TupleCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 535, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 536, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\nTypeError: an integer is required\n\n\tat org.apache.beam.runners.fnexecution.control.FnApiControlClient$ResponseStreamObserver.onNext(FnApiControlClient.java:180)\n\tat org.apache.beam.runners.fnexecution.control.FnApiControlClient$ResponseStreamObserver.onNext(FnApiControlClient.java:160)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Contexts$ContextualizedServerCallListener.onMessage(Contexts.java:76)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\n\t... 3 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ds2\u001b[38;5;241m.\u001b[39mprint()\n\u001b[0;32m----> 2\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pyflink/datastream/stream_execution_environment.py:761\u001b[0m, in \u001b[0;36mStreamExecutionEnvironment.execute\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03mTriggers the program execution. The environment will execute all parts of\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124;03mthe program that have resulted in a \"sink\" operation. Sink operations are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;124;03m:return: The result of the job execution, containing elapsed time and accumulators.\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    760\u001b[0m j_stream_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_stream_graph(clear_transformations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[0;32m--> 761\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m JobExecutionResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_j_stream_execution_environment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_stream_graph\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pyflink/util/exceptions.py:146\u001b[0m, in \u001b[0;36mcapture_java_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjava_gateway\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_gateway\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o0.execute.\n: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:144)\n\tat org.apache.flink.runtime.minicluster.MiniClusterJobClient.lambda$getJobExecutionResult$3(MiniClusterJobClient.java:141)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$1(AkkaInvocationHandler.java:259)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1389)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)\n\tat akka.dispatch.OnComplete.internal(Future.scala:300)\n\tat akka.dispatch.OnComplete.internal(Future.scala:297)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:68)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)\n\tat akka.pattern.PromiseActorRef.$bang(AskSupport.scala:621)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:532)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)\nCaused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy\n\tat org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138)\n\tat org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:301)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:291)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:282)\n\tat org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:739)\n\tat org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:78)\n\tat org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:443)\n\tat sun.reflect.GeneratedMethodAccessor18.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:304)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:302)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:217)\n\tat org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:78)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:163)\n\tat akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)\n\tat akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)\n\tat scala.PartialFunction.applyOrElse(PartialFunction.scala:123)\n\tat scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)\n\tat akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:535)\n\tat akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:580)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:548)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\t... 4 more\nCaused by: java.lang.RuntimeException: Error while waiting for BeamPythonFunctionRunner flush\n\tat org.apache.flink.streaming.api.operators.python.AbstractExternalPythonFunctionOperator.invokeFinishBundle(AbstractExternalPythonFunctionOperator.java:106)\n\tat org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.processWatermark(AbstractPythonFunctionOperator.java:184)\n\tat org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitWatermark(OneInputStreamTask.java:239)\n\tat org.apache.flink.streaming.runtime.watermarkstatus.StatusWatermarkValve.findAndOutputNewMinWatermarkAcrossAlignedChannels(StatusWatermarkValve.java:200)\n\tat org.apache.flink.streaming.runtime.watermarkstatus.StatusWatermarkValve.inputWatermark(StatusWatermarkValve.java:105)\n\tat org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:136)\n\tat org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:105)\n\tat org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:519)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:203)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:804)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:753)\n\tat org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:948)\n\tat org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:927)\n\tat org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:741)\n\tat org.apache.flink.runtime.taskmanager.Task.run(Task.java:563)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.RuntimeException: Failed to close remote bundle\n\tat org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.finishBundle(BeamPythonFunctionRunner.java:382)\n\tat org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.flush(BeamPythonFunctionRunner.java:366)\n\tat org.apache.flink.streaming.api.operators.python.AbstractExternalPythonFunctionOperator.lambda$invokeFinishBundle$0(AbstractExternalPythonFunctionOperator.java:85)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Error received from SDK harness for instruction 1: Traceback (most recent call last):\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n    response = task()\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n    lambda: self.create_worker().do_instruction(request), request)\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 606, in do_instruction\n    return getattr(self, request_type)(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n    bundle_processor.process_bundle(instruction_id))\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 999, in process_bundle\n    input_op_by_transform_id[element.transform_id].process_encoded(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n    self.output(decoded_value)\n  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 104, in pyflink.fn_execution.beam.beam_operations_fast.IntermediateOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 92, in pyflink.fn_execution.beam.beam_operations_fast.NetworkOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_coder_impl_fast.pyx\", line 101, in pyflink.fn_execution.beam.beam_coder_impl_fast.FlinkLengthPrefixCoderBeamWrapper.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 270, in pyflink.fn_execution.coder_impl_fast.IterableCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 398, in pyflink.fn_execution.coder_impl_fast.RowCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 877, in pyflink.fn_execution.coder_impl_fast.TupleCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 535, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 536, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\nTypeError: an integer is required\n\n\tat java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)\n\tat java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)\n\tat org.apache.beam.sdk.util.MoreFutures.get(MoreFutures.java:60)\n\tat org.apache.beam.runners.fnexecution.control.SdkHarnessClient$BundleProcessor$ActiveBundle.close(SdkHarnessClient.java:504)\n\tat org.apache.beam.runners.fnexecution.control.DefaultJobBundleFactory$SimpleStageBundleFactory$1.close(DefaultJobBundleFactory.java:555)\n\tat org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.finishBundle(BeamPythonFunctionRunner.java:380)\n\t... 7 more\nCaused by: java.lang.RuntimeException: Error received from SDK harness for instruction 1: Traceback (most recent call last):\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n    response = task()\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n    lambda: self.create_worker().do_instruction(request), request)\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 606, in do_instruction\n    return getattr(self, request_type)(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n    bundle_processor.process_bundle(instruction_id))\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 999, in process_bundle\n    input_op_by_transform_id[element.transform_id].process_encoded(\n  File \"/home/krish/miniconda3/lib/python3.8/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n    self.output(decoded_value)\n  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 104, in pyflink.fn_execution.beam.beam_operations_fast.IntermediateOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 158, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 174, in pyflink.fn_execution.beam.beam_operations_fast.FunctionOperation.process\n  File \"pyflink/fn_execution/beam/beam_operations_fast.pyx\", line 92, in pyflink.fn_execution.beam.beam_operations_fast.NetworkOutputProcessor.process_outputs\n  File \"pyflink/fn_execution/beam/beam_coder_impl_fast.pyx\", line 101, in pyflink.fn_execution.beam.beam_coder_impl_fast.FlinkLengthPrefixCoderBeamWrapper.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 270, in pyflink.fn_execution.coder_impl_fast.IterableCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 398, in pyflink.fn_execution.coder_impl_fast.RowCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 877, in pyflink.fn_execution.coder_impl_fast.TupleCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 535, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\n  File \"pyflink/fn_execution/coder_impl_fast.pyx\", line 536, in pyflink.fn_execution.coder_impl_fast.BigIntCoderImpl.encode_to_stream\nTypeError: an integer is required\n\n\tat org.apache.beam.runners.fnexecution.control.FnApiControlClient$ResponseStreamObserver.onNext(FnApiControlClient.java:180)\n\tat org.apache.beam.runners.fnexecution.control.FnApiControlClient$ResponseStreamObserver.onNext(FnApiControlClient.java:160)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Contexts$ContextualizedServerCallListener.onMessage(Contexts.java:76)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\n\tat org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\n\t... 3 more\n"
     ]
    }
   ],
   "source": [
    "ds2.print()\n",
    "env.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef4449-584c-49d1-b1e1-9c40df648457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyKeyedProcessFunction(KeyedProcessFunction):\n",
    "\n",
    "    def open(self, runtime_context: RuntimeContext):\n",
    "        state_desc = MapStateDescriptor('map', Types.LONG(), Types.LONG())\n",
    "        self.state = runtime_context.get_map_state(state_desc)\n",
    "\n",
    "    def process_element(self, value, ctx: 'KeyedProcessFunction.Context'):\n",
    "        if not self.state.contains(value[0]):\n",
    "            result = value[1]\n",
    "            self.state.put(value[0], result)\n",
    "        else:\n",
    "            existing = self.state.get(value[0])\n",
    "            if existing <= 10:\n",
    "                result = value[1] + existing\n",
    "                self.state.put(value[0], result)\n",
    "            else:\n",
    "                result = existing\n",
    "        yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75eb4c0-44e7-4a8b-a5ea-452eb1ffdacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
